# AUTOGENERATED! DO NOT EDIT! File to edit: ../../notebooks/04-density-db-food-match.ipynb.

# %% auto 0
__all__ = ['root', 'col_types', 'split_types', 'sort_order', 'fuzzy_search', 'transform_ingredient', 'search_food_df',
           'calculate_search_stats', 'select_from_searches', 'select_from_search_ids', 'match_ingredient',
           'select_cols', 'create_na_synonyms_df', 'get_column_synonyms']

# %% ../../notebooks/04-density-db-food-match.ipynb 5
from pyprojroot import here
root = here()
import sys
sys.path.append(str(root))

# %% ../../notebooks/04-density-db-food-match.ipynb 6
import pandas as pd
import numpy as np
import pyarrow as pa
import seaborn as sns

from pyprojroot import here
root = here()

from ..utils.join_utils import *

import nltk
from nltk.corpus import wordnet
import spacy
from spacy.matcher import Matcher
from spacy.util import filter_spans

from thefuzz import fuzz

from sentence_transformers import SentenceTransformer
from sentence_transformers.util import cos_sim
import torch
from sklearn.metrics.pairwise import cosine_similarity

import re
import json
import pickle
from itertools import groupby

from tqdm import tqdm
tqdm.pandas()

from ..utils.utils import *

# %% ../../notebooks/04-density-db-food-match.ipynb 7
pd.options.mode.chained_assignment = None  # default='warn'

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# %% ../../notebooks/04-density-db-food-match.ipynb 10
col_types = ['name.name', 'name.description']
split_types = ['nouns', 'others']

# %% ../../notebooks/04-density-db-food-match.ipynb 19
def fuzzy_search(food_df_description, search_word, threshold=90):

    if not search_word:
        return False
    
    # check if full word match of the *words in string*
    if contains_whole_word(food_df_description, search_word):
        return True

    # check levenstain distance of the *string*
    fuzzy_score = fuzz.ratio(food_df_description, search_word)
    if fuzzy_score >= threshold:
        return True
    
    return False

# %% ../../notebooks/04-density-db-food-match.ipynb 25
with open(f'{root}/config/density/ingredient_transforms.json', 'r') as f:
    default_transforms = json.load(f)

# %% ../../notebooks/04-density-db-food-match.ipynb 26
def transform_ingredient(ingredient):
    ingredient = ingredient[ingredient.notnull()]
    for defualt_instance in default_transforms.values():
        matches = [key_word in ingredient.values for key_word in defualt_instance['key']]
        if all(matches):
            if len(matches) == len(ingredient.index[ingredient.index.str.startswith('name.name.nouns')]): # only match if there are no additional ingredient name nouns
                transformed = pd.Series(defualt_instance['value'], dtype='string', name=ingredient.name)
                transformed = pd.concat([transformed, ingredient[~ingredient.index.str.startswith('name.name.nouns')]])
                transformed = transformed[transformed.notnull()]
                return transformed
    return ingredient

# %% ../../notebooks/04-density-db-food-match.ipynb 37
def search_food_df(ingredient, exploded_food_df, debug=False):

    ingredient = ingredient[ingredient.notnull()]
    if ingredient.empty: return np.array([])

    matched_idxs = []

    if debug: debug_idxs = {col: {} for col in ingredient.index}

    for search_col, search_word in ingredient.items():
            
            matched_food_df = exploded_food_df.loc[matched_idxs] if matched_idxs else exploded_food_df
            current_match_idxs = set(matched_food_df.index[matched_food_df['description'].apply(fuzzy_search, args=(search_word,))])
            if debug: debug_idxs[search_col] = {'value': search_word, 'size': len(current_match_idxs), 'idxs': {'fuzzy': current_match_idxs, 'current': current_match_idxs}}

            if len(current_match_idxs): matched_idxs.extend(current_match_idxs)
            if debug: debug_idxs[search_col]['idxs']['selected'] = matched_idxs
    
    matched_idxs = np.array(matched_idxs)
    
    if debug:
        return matched_idxs, debug_idxs
    else:
        return matched_idxs

# %% ../../notebooks/04-density-db-food-match.ipynb 42
with open(f'{root}/config/default_words.json', 'r') as f:
    default_words = json.load(f)['density']

with open(f'{root}/config/exclusion_words.json', 'r') as f:
    exclusion_words = json.load(f)['density']

def calculate_search_stats(food_descriptions, ingredient_values):

    ingredient_noun_values, ingredient_other_values = ingredient_values[:2]
    ingredient_description_values = [*ingredient_values[2], *ingredient_values[3]]

    ingredient_match_position = 99
    description_match_position = 99
    description_match_word_count = 99
    ingredient_nouns_match_count = 0
    ingredient_nouns_whole_match_count = 0
    ingredient_others_match_count = 0
    ingredient_others_whole_match_count = 0
    ingredient_description_match_count = 0
    default_word_count = 0
    exclusion_word_count = 0
    remaining_word_count = 99

    for description_idx, food_description in enumerate(food_descriptions):

        noun_matches = [(ingredient_idx, ingredient_noun_value) for ingredient_idx, ingredient_noun_value in enumerate(ingredient_noun_values)
                if fuzzy_search(food_description, ingredient_noun_value)]
        if noun_matches:
            if description_match_position == 99: 
                description_match_position = description_idx - default_word_count # not including default words in description eg. spice, cinammon.
                description_match_word_count = len(food_description.split(' '))
            if ingredient_match_position == 99: ingredient_match_position = noun_matches[0][0]
            ingredient_noun_values = [value for i, value in enumerate(ingredient_noun_values) if i not in list(zip(*noun_matches))[0]]
        ingredient_nouns_match_count += len(noun_matches)
        ingredient_nouns_whole_match_count += len([noun_match for noun_match in noun_matches if contains_whole_word(food_description, noun_match[1])])

        description_matches = [(ingredient_idx, ingredient_description_value) for ingredient_idx, ingredient_description_value in enumerate(ingredient_description_values)
                if fuzzy_search(food_description, ingredient_description_value)]
        ingredient_description_match_count += len(description_matches)

        other_matches = [(ingredient_idx, ingredient_other_value) for ingredient_idx, ingredient_other_value in enumerate(ingredient_other_values)
                if fuzzy_search(food_description, ingredient_other_value)]
        ingredient_others_match_count += len(other_matches)
        ingredient_others_whole_match_count += len([other_match for other_match in other_matches if contains_whole_word(food_description, other_match[1])])
        if other_matches: 
            ingredient_other_values = [value for i, value in enumerate(ingredient_other_values) if i not in list(zip(*other_matches))[0]] # removing so it can't match twice
        default_word_count += len([default_word for default_word in default_words if contains_whole_word(food_description, default_word)])
        exclusion_word_count += len([exclusion_word for exclusion_word in exclusion_words if contains_whole_word(food_description, exclusion_word)])


    remaining_word_count = np.sum([len(food_description.split(" ")) for food_description in food_descriptions]) + len(ingredient_other_values) - default_word_count - ingredient_nouns_whole_match_count - ingredient_others_match_count 

    return (
        ingredient_match_position,
        description_match_position,
        description_match_word_count,
        ingredient_nouns_match_count,
        ingredient_nouns_whole_match_count,
        ingredient_others_match_count,
        ingredient_others_whole_match_count,
        ingredient_description_match_count,
        default_word_count,
        exclusion_word_count,
        remaining_word_count
    )

# %% ../../notebooks/04-density-db-food-match.ipynb 44
sort_order = {
    'ingredient_nouns_whole_match_count': False,
    'ingredient_nouns_match_count': False,
    'exclusion_word_count': True,
    'description_match_position': True,
    'ingredient_match_position': True,
    'description_match_word_count': True,
    'ingredient_others_whole_match_count': False,
    'ingredient_others_match_count': False,
    'ingredient_description_match_count': False,
    'default_word_count': False,
    'description_remaining_word_count': True,
    'description_list_length': True,
    'data_type': True
}

# %% ../../notebooks/04-density-db-food-match.ipynb 45
def select_from_searches(match_df, ingredient, unit_type, return_df=False):
    
    ingredient_names = []
    for name_type in ['name', 'description']:
        for word_type in ['nouns', 'others']:
            name_cols = [col for col in ingredient.index[ingredient.notnull()] if col.startswith(f'name.{name_type}.{word_type}')]
            name_cols.reverse()
            ingredient_names.append(ingredient[name_cols].values)

    match_df['ingredient_match_position'], \
    match_df['description_match_position'],\
    match_df['description_match_word_count'],\
    match_df['ingredient_nouns_match_count'],\
    match_df['ingredient_nouns_whole_match_count'],\
    match_df['ingredient_others_match_count'],\
    match_df['ingredient_others_whole_match_count'],\
    match_df['ingredient_description_match_count'],\
    match_df['default_word_count'],\
    match_df['exclusion_word_count'],\
    match_df['description_remaining_word_count'] = zip(*match_df['description_list'].apply(calculate_search_stats, args=(ingredient_names, )))
    
    # ordering dataset by priority
    sort_order_local = list(zip(*{f'{unit_type}_exists': False, **sort_order}.items()))
    match_df = match_df.sort_values(
        by=list(sort_order_local[0]), ascending=list(sort_order_local[1])
    )

    if return_df:
        result = match_df.reindex(columns=['description_list', *list(sort_order_local[0])])
    else:
        result = match_df.iloc[0].name if not match_df.empty else pd.NA

    return result

# %% ../../notebooks/04-density-db-food-match.ipynb 48
def select_from_search_ids(ingredient, food_df):

    ingredient = ingredient[ingredient.notnull()]
    if ingredient.empty: return pd.NA

    unit_type = ingredient['unit_type']
    if unit_type == 'weight': return pd.NA
    ingredient = ingredient.drop('unit_type')

    search_ids = ingredient['search_ids']
    if (isinstance(search_ids, np.ndarray) and not search_ids.size) or (isinstance(search_ids, type(pd.NA))): return pd.NA
    ingredient = ingredient.drop('search_ids')

    search_df = food_df.loc[search_ids]

    return select_from_searches(search_df, ingredient, unit_type)

# %% ../../notebooks/04-density-db-food-match.ipynb 52
def match_ingredient(ingredient, food_df, exploded_food_df):

    unit_type = ingredient['unit_type']
    if unit_type == 'weight': return pd.NA
    ingredient = ingredient.drop('unit_type')

    ingredient = ingredient[ingredient.notnull()]
    if ingredient.empty: return pd.NA

    ingredient = transform_ingredient(ingredient)

    searched_df = food_df.loc[search_food_df(ingredient, exploded_food_df)]
    if searched_df.empty: return pd.NA

    selected_food_idx = select_from_searches(searched_df, ingredient, unit_type)
    
    return selected_food_idx

# %% ../../notebooks/04-density-db-food-match.ipynb 74
def select_cols(df, cols, limit): 
    df_cols = df.columns[df.columns.str.contains(cols)]
    return list(df_cols[-limit:])

def create_na_synonyms_df(na_expanded_ingredients_df):

    selected_cols = na_expanded_ingredients_df.columns
    selected_cols = [selected_cols[selected_cols.str.contains(search)] for search in ['name.name.nouns', 'name.description.nouns', 'name.name.others']]
    selected_cols = pd.Series([x for xs in selected_cols for x in xs], dtype='string')
    selected_cols = [selected_cols[selected_cols.str.contains(search)] for search in ['0','1']]
    selected_cols = pd.Series([x for xs in selected_cols for x in xs], dtype='string')

    remainder_cols = [col for col in na_expanded_ingredients_df.columns if col not in selected_cols]

    na_synonyms_df = get_column_synonyms(na_expanded_ingredients_df[selected_cols].copy(deep=True))

    # na_synonyms_df = na_synonyms_df.join(na_expanded_ingredients_df[remainder_cols].copy(deep=True))

    na_synonyms_df = na_synonyms_df.astype('string')

    return na_synonyms_df

def get_column_synonyms(df):
    
    for col in df.columns:
        df[col] = df[col].apply(find_alt_words)

    df = df.map(lambda x: [] if not isinstance(x, list) else x)

    for col in df.columns:
        expanded = pd.DataFrame(df[col].tolist(), index=df.index, dtype='string[pyarrow]')
        expanded.columns = [col + '.' + str(c) for c in expanded.columns]
        df = df.join(expanded)
        df.drop(columns=[col], inplace=True)

    return df
